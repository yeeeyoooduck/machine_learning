{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yeeeyoooduck/PycharmProjects/MachineLearning/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/yeeeyoooduck/PycharmProjects/MachineLearning/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/yeeeyoooduck/PycharmProjects/MachineLearning/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/yeeeyoooduck/PycharmProjects/MachineLearning/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика точности на первой половине данных: 0.8421052631578947\n",
      "Метрика точности на случайно разделенных данных: 0.8552631578947368\n",
      "Метрики точности для нескольких повторов с использованием библиотечной функции:\n",
      "Попытка 1: 0.8486842105263158\n",
      "Попытка 2: 0.7763157894736842\n",
      "Попытка 3: 0.8026315789473685\n",
      "Попытка 4: 0.7960526315789473\n",
      "Попытка 5: 0.8289473684210527\n",
      "Матрица классификации для обучающей выборки:\n",
      "[[56 12]\n",
      " [ 6 77]]\n",
      "Матрица классификации для тестовой выборки:\n",
      "[[57 13]\n",
      " [11 71]]\n",
      "Отчёт о классификации для обучающей выборки:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.86        68\n",
      "           1       0.87      0.93      0.90        83\n",
      "\n",
      "    accuracy                           0.88       151\n",
      "   macro avg       0.88      0.88      0.88       151\n",
      "weighted avg       0.88      0.88      0.88       151\n",
      "\n",
      "Отчёт о классификации для тестовой выборки:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83        70\n",
      "           1       0.85      0.87      0.86        82\n",
      "\n",
      "    accuracy                           0.84       152\n",
      "   macro avg       0.84      0.84      0.84       152\n",
      "weighted avg       0.84      0.84      0.84       152\n",
      "\n",
      "Метрики эффективности классификации для обучающей выборки:\n",
      "Precision: 0.8651685393258427\n",
      "Recall: 0.927710843373494\n",
      "F1-score: 0.8953488372093024\n",
      "Метрики эффективности классификации для тестовой выборки:\n",
      "Precision: 0.8452380952380952\n",
      "Recall: 0.8658536585365854\n",
      "F1-score: 0.8554216867469879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yeeeyoooduck/PycharmProjects/MachineLearning/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/yeeeyoooduck/PycharmProjects/MachineLearning/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/yeeeyoooduck/PycharmProjects/MachineLearning/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('heart.csv')\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = data.drop(columns=['output'])\n",
    "y = data['output']\n",
    "\n",
    "# Разделение датасета на обучающую и тестовую выборки (первая половина)\n",
    "X_train_half, X_test_half, y_train_half, y_test_half = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# Обучение модели на первой половине данных\n",
    "model_half = LogisticRegression()\n",
    "model_half.fit(X_train_half, y_train_half)\n",
    "\n",
    "# Предсказание на тестовой половине данных и расчёт метрики accuracy\n",
    "y_pred_half = model_half.predict(X_test_half)\n",
    "accuracy_half = accuracy_score(y_test_half, y_pred_half)\n",
    "\n",
    "print(\"Метрика точности на первой половине данных:\", accuracy_half)\n",
    "\n",
    "# Разделение датасета на обучающую и тестовую выборки (случайное разделение)\n",
    "X_train_random, X_test_random, y_train_random, y_test_random = train_test_split(X, y, test_size=0.5, random_state=None)\n",
    "\n",
    "# Обучение модели на случайно разделенных данных\n",
    "model_random = LogisticRegression()\n",
    "model_random.fit(X_train_random, y_train_random)\n",
    "\n",
    "# Предсказание на тестовой случайно разделенной выборке и расчёт метрики accuracy\n",
    "y_pred_random = model_random.predict(X_test_random)\n",
    "accuracy_random = accuracy_score(y_test_random, y_pred_random)\n",
    "\n",
    "print(\"Метрика точности на случайно разделенных данных:\", accuracy_random)\n",
    "\n",
    "# Повторение анализа с использованием библиотечной функции train_test_split несколько раз\n",
    "accuracies = []\n",
    "for _ in range(5):\n",
    "    X_train_lib, X_test_lib, y_train_lib, y_test_lib = train_test_split(X, y, test_size=0.5)\n",
    "    model_lib = LogisticRegression()\n",
    "    model_lib.fit(X_train_lib, y_train_lib)\n",
    "    y_pred_lib = model_lib.predict(X_test_lib)\n",
    "    accuracy_lib = accuracy_score(y_test_lib, y_pred_lib)\n",
    "    accuracies.append(accuracy_lib)\n",
    "\n",
    "print(\"Метрики точности для нескольких повторов с использованием библиотечной функции:\")\n",
    "for i, acc in enumerate(accuracies):\n",
    "    print(f\"Попытка {i+1}: {acc}\")\n",
    "\n",
    "# Построение матрицы классификации и отчёта о классификации\n",
    "confusion_matrix_train = confusion_matrix(y_train_half, model_half.predict(X_train_half))\n",
    "confusion_matrix_test = confusion_matrix(y_test_half, y_pred_half)\n",
    "\n",
    "print(\"Матрица классификации для обучающей выборки:\")\n",
    "print(confusion_matrix_train)\n",
    "print(\"Матрица классификации для тестовой выборки:\")\n",
    "print(confusion_matrix_test)\n",
    "\n",
    "classification_report_train = classification_report(y_train_half, model_half.predict(X_train_half))\n",
    "classification_report_test = classification_report(y_test_half, y_pred_half)\n",
    "\n",
    "print(\"Отчёт о классификации для обучающей выборки:\")\n",
    "print(classification_report_train)\n",
    "print(\"Отчёт о классификации для тестовой выборки:\")\n",
    "print(classification_report_test)\n",
    "\n",
    "# Расчёт всех метрик эффективности классификации\n",
    "precision_train = precision_score(y_train_half, model_half.predict(X_train_half))\n",
    "recall_train = recall_score(y_train_half, model_half.predict(X_train_half))\n",
    "f1_train = f1_score(y_train_half, model_half.predict(X_train_half))\n",
    "\n",
    "precision_test = precision_score(y_test_half, y_pred_half)\n",
    "recall_test = recall_score(y_test_half, y_pred_half)\n",
    "f1_test = f1_score(y_test_half, y_pred_half)\n",
    "\n",
    "print(\"Метрики эффективности классификации для обучающей выборки:\")\n",
    "print(\"Precision:\", precision_train)\n",
    "print(\"Recall:\", recall_train)\n",
    "print(\"F1-score:\", f1_train)\n",
    "\n",
    "print(\"Метрики эффективности классификации для тестовой выборки:\")\n",
    "print(\"Precision:\", precision_test)\n",
    "print(\"Recall:\", recall_test)\n",
    "print(\"F1-score:\", f1_test)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T13:52:04.214280Z",
     "start_time": "2024-04-04T13:52:03.742541Z"
    }
   },
   "id": "cbaafaa085c95c3d",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Повторите анализ для других видов моделей. Используйте 5-10 разных классов моделей. Подсчитывайте только метрики на тестовой выборке.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58e7c37564d65865"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель: Logistic Regression\n",
      "Accuracy: 0.8289473684210527\n",
      "Precision: 0.8414634146341463\n",
      "Recall: 0.8414634146341463\n",
      "F1-score: 0.8414634146341463\n",
      "==================================================\n",
      "Модель: K Nearest Neighbors\n",
      "Accuracy: 0.6447368421052632\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.6829268292682927\n",
      "F1-score: 0.6746987951807228\n",
      "==================================================\n",
      "Модель: Support Vector Machine\n",
      "Accuracy: 0.6644736842105263\n",
      "Precision: 0.6260162601626016\n",
      "Recall: 0.9390243902439024\n",
      "F1-score: 0.751219512195122\n",
      "==================================================\n",
      "Модель: Decision Tree\n",
      "Accuracy: 0.743421052631579\n",
      "Precision: 0.7792207792207793\n",
      "Recall: 0.7317073170731707\n",
      "F1-score: 0.7547169811320755\n",
      "==================================================\n",
      "Модель: Random Forest\n",
      "Accuracy: 0.8289473684210527\n",
      "Precision: 0.85\n",
      "Recall: 0.8292682926829268\n",
      "F1-score: 0.8395061728395061\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('heart.csv')\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = data.drop(columns=['output'])\n",
    "y = data['output']\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# Список моделей\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"K Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# Обучение и оценка всех моделей\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"Модель: {name}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-score: {f1}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# Логистическая регрессия и случайный лес выглядят наиболее подходящими для данной задачи классификации сердечных заболеваний, но необходимо учитывать контекст и требования вашего приложения при выборе оптимальной модели."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T14:20:44.148864Z",
     "start_time": "2024-04-04T14:20:43.030Z"
    }
   },
   "id": "e0f98d411ca47190",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Повторите анализ для другого датасета по вашему выбору. Используйте несколько моделей для сравнения. Используйте датасет для множественной классификации."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f45a14d1d0f58e52"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель: Logistic Regression\n",
      "Accuracy: 0.9555555555555556\n",
      "Precision: 0.9614814814814815\n",
      "Recall: 0.9555555555555556\n",
      "F1-score: 0.9552910052910052\n",
      "==================================================\n",
      "Модель: K Nearest Neighbors\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n",
      "==================================================\n",
      "Модель: Support Vector Machine\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n",
      "==================================================\n",
      "Модель: Decision Tree\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n",
      "==================================================\n",
      "Модель: Random Forest\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Загрузка данных\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Список моделей\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, multi_class='ovr'),\n",
    "    \"K Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# Обучение и оценка всех моделей\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(f\"Модель: {name}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-score: {f1}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# Можно заключить, что все модели хорошо справляются с классификацией на наборе данных Iris. В частности, K ближайших соседей, метод опорных векторов, решающее дерево и случайный лес достигают идеальной производительности, что свидетельствует о хорошем качестве данных и способности моделей к их обучению."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T14:24:47.949661Z",
     "start_time": "2024-04-04T14:24:47.401889Z"
    }
   },
   "id": "ade25c7137cfbe0f",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Повторите анализ для датасета, предназначенного для решения задачи регрессии. Используйте все метрики качества регрессии, изученные на лекции. Постройте 5 - 10 разных моделей регрессии."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d114946bd6c821d3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель: Linear Regression\n",
      "Mean Squared Error (MSE): 21.517444231177723\n",
      "Mean Absolute Error (MAE): 3.162709871457465\n",
      "R^2 Score: 0.7112260057484863\n",
      "==================================================\n",
      "Модель: Ridge Regression\n",
      "Mean Squared Error (MSE): 22.04405308986103\n",
      "Mean Absolute Error (MAE): 3.1785390760345584\n",
      "R^2 Score: 0.7041586727559432\n",
      "==================================================\n",
      "Модель: Lasso Regression\n",
      "Mean Squared Error (MSE): 25.63950292804399\n",
      "Mean Absolute Error (MAE): 3.658797629197879\n",
      "R^2 Score: 0.655906082915434\n",
      "==================================================\n",
      "Модель: ElasticNet Regression\n",
      "Mean Squared Error (MSE): 25.4051963642821\n",
      "Mean Absolute Error (MAE): 3.637139431317784\n",
      "R^2 Score: 0.6590505847238237\n",
      "==================================================\n",
      "Модель: Decision Tree Regressor\n",
      "Mean Squared Error (MSE): 11.996973684210527\n",
      "Mean Absolute Error (MAE): 2.531578947368421\n",
      "R^2 Score: 0.8389950975357935\n",
      "==================================================\n",
      "Модель: Random Forest Regressor\n",
      "Mean Squared Error (MSE): 10.325165460526314\n",
      "Mean Absolute Error (MAE): 2.1528684210526317\n",
      "R^2 Score: 0.8614315325133408\n",
      "==================================================\n",
      "Модель: Gradient Boosting Regressor\n",
      "Mean Squared Error (MSE): 7.885543194588111\n",
      "Mean Absolute Error (MAE): 2.0496511164523916\n",
      "R^2 Score: 0.8941723849413034\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Загрузка данных\n",
    "boston = fetch_openml(data_id=531)\n",
    "\n",
    "# Преобразование в DataFrame\n",
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "y = boston.target\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Преобразование строковых значений в числовые\n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "\n",
    "# Список моделей регрессии\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(),\n",
    "    \"Lasso Regression\": Lasso(),\n",
    "    \"ElasticNet Regression\": ElasticNet(),\n",
    "    \"Decision Tree Regressor\": DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"Gradient Boosting Regressor\": GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "# Обучение и оценка всех моделей\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"Модель: {name}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"R^2 Score: {r2}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# Из вывода видно, что регрессоры градиентного бустинга и случайного леса показывают лучшие результаты с наименьшей среднеквадратичной ошибкой и наивысшим коэффициентом детерминации."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T14:32:57.642765Z",
     "start_time": "2024-04-04T14:32:56.767013Z"
    }
   },
   "id": "1b129d76b5af4e0c",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "62a088d9b891d57"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
